---
title: DataLoader - Pipeline
description: Learn about DataLoader features in Lavender Data including shuffling, fault tolerance, and resumable iterations
---


Use pipeline modules on data loading with `filters`, `collater`, and `preprocessors` parameters.

Filters determine which samples to include or exclude during iteration.

```python
iteration = LavenderDataLoader(
    dataset_id=dataset.id,
    shardsets=[shardset.id],
    filters=[("uid_mod", {"mod": 2})],  # To give a parameter to the module, use a tuple (name, params)
    batch_size=10,
)
```


Collaters control how individual samples are combined into batches.

```python
iteration = LavenderDataLoader(
    dataset_id=dataset.id,
    shardsets=[shardset.id],
    collater="pylist", # To use a module without parameters, specify the module name only
    batch_size=10,
)
```


Preprocessors transform batches before they're returned to your application.

```python
iteration = LavenderDataLoader(
    dataset_id=dataset.id,
    shardsets=[shardset.id],
    preprocessors=["append_new_column"],
    batch_size=10,
)
```
